MCMCTREE in paml version 4.9j, February 2020

Reading options from mcmctree.ctl..
finetune is deprecated now.
Reading master tree.
(((And_ful, And_hae), ((And_tri, (And_bic, And_mar)), And_hat)), (Apis_mel, (Bom_con, ((Bom_syl, (Bom_pas, (Bom_vet, Bom_mus))), (Bom_hyp, Bom_hor)))));

Reading sequence data..  3 loci


*** Locus 1 ***
ns = 14  	ls = 14982
Reading sequences, sequential format..
Reading seq # 1: And_bic       Reading seq # 2: And_ful       Reading seq # 3: And_hae       Reading seq # 4: And_hat       Reading seq # 5: And_mar       Reading seq # 6: And_tri       Reading seq # 7: Apis_mel       Reading seq # 8: Bom_con       Reading seq # 9: Bom_hor       Reading seq #10: Bom_hyp       Reading seq #11: Bom_mus       Reading seq #12: Bom_pas       Reading seq #13: Bom_syl       Reading seq #14: Bom_vet       
Sequences read..
Counting site patterns..  0:00
Compressing,   1039 patterns at  10000 /  14982 sites (66.7%),  0:00Compressing,   1200 patterns at  14982 /  14982 sites (100.0%),  0:00
Collecting fpatt[] & pose[],   1200 patterns at  10000 /  14982 sites (66.7%),  0:00Collecting fpatt[] & pose[],   1200 patterns at  14982 /  14982 sites (100.0%),  0:00
Counting frequencies..
1200 patterns, messy


*** Locus 2 ***
ns = 14  	ls = 14987
Reading sequences, sequential format..
Reading seq # 1: And_bic       Reading seq # 2: And_ful       Reading seq # 3: And_hae       Reading seq # 4: And_hat       Reading seq # 5: And_mar       Reading seq # 6: And_tri       Reading seq # 7: Apis_mel       Reading seq # 8: Bom_con       Reading seq # 9: Bom_hor       Reading seq #10: Bom_hyp       Reading seq #11: Bom_mus       Reading seq #12: Bom_pas       Reading seq #13: Bom_syl       Reading seq #14: Bom_vet       
Sequences read..
Counting site patterns..  0:00
Compressing,    776 patterns at  10000 /  14987 sites (66.7%),  0:00Compressing,    941 patterns at  14987 /  14987 sites (100.0%),  0:00
Collecting fpatt[] & pose[],    941 patterns at  10000 /  14987 sites (66.7%),  0:00Collecting fpatt[] & pose[],    941 patterns at  14987 /  14987 sites (100.0%),  0:00
Counting frequencies..
941 patterns, messy


*** Locus 3 ***
ns = 14  	ls = 14999
Reading sequences, sequential format..
Reading seq # 1: And_bic       Reading seq # 2: And_ful       Reading seq # 3: And_hae       Reading seq # 4: And_hat       Reading seq # 5: And_mar       Reading seq # 6: And_tri       Reading seq # 7: Apis_mel       Reading seq # 8: Bom_con       Reading seq # 9: Bom_hor       Reading seq #10: Bom_hyp       Reading seq #11: Bom_mus       Reading seq #12: Bom_pas       Reading seq #13: Bom_syl       Reading seq #14: Bom_vet       
Sequences read..
Counting site patterns..  0:00
Compressing,   2062 patterns at  10000 /  14999 sites (66.7%),  0:00Compressing,   2708 patterns at  14999 /  14999 sites (100.0%),  0:00
Collecting fpatt[] & pose[],   2708 patterns at  10000 /  14999 sites (66.7%),  0:00Collecting fpatt[] & pose[],   2708 patterns at  14999 /  14999 sites (100.0%),  0:00
Counting frequencies..
2708 patterns, messy


Fossil calibration information used.
Node  15:   U (  1.2000,  0.0250 )
Node  18:   B (  0.1600,  0.1800,  0.0250,  0.0250 )
Node  21:   B (  0.9000,  1.2000,  0.0250,  0.0250 )
Node  22:   B (  0.2500,  0.4000,  0.0250,  0.0250 )
Node  27:   B (  0.2000,  0.2200,  0.0250,  0.0250 )

4034368 bytes for conP
648 bytes for rates.

2000 burnin, sampled every 60, 60000 samples
Approximating posterior
(Settings: cleandata=0  print=1  saveconP=1)

getting initial values to start MCMC.

*** min-age round  1: from nodes  21 (  1.05351) to  15,   2 nodes 
************
Species tree
ns = 14  nnode = 27
 father   node  name              time     sons          fossil
     17      1  And_ful           0.00000
     17      2  And_hae           0.00000
     19      3  And_tri           0.00000
     20      4  And_bic           0.00000
     20      5  And_mar           0.00000
     18      6  And_hat           0.00000
     21      7  Apis_mel          0.00000
     22      8  Bom_con           0.00000
     24      9  Bom_syl           0.00000
     25     10  Bom_pas           0.00000
     26     11  Bom_vet           0.00000
     26     12  Bom_mus           0.00000
     27     13  Bom_hyp           0.00000
     27     14  Bom_hor           0.00000
      0     15                    1.19252  (16 21)  U ( 1.2000, 0.0250 ) 
     15     16                    0.91412  (17 18)
     16     17                    0.84199  ( 1  2)
     16     18                    0.17005  (19  6)  B ( 0.1600, 0.1800, 0.0250, 0.0250 ) 
     18     19                    0.07652  ( 3 20)
     19     20                    0.02854  ( 4  5)
     15     21                    1.05351  ( 7 22)  B ( 0.9000, 1.2000, 0.0250, 0.0250 ) 
     21     22                    0.33268  ( 8 23)  B ( 0.2500, 0.4000, 0.0250, 0.0250 ) 
     22     23                    0.27613  (24 27)
     23     24                    0.17177  ( 9 25)
     24     25                    0.12103  (10 26)
     25     26                    0.09814  (11 12)
     23     27                    0.21411  (13 14)  B ( 0.2000, 0.2200, 0.0250, 0.0250 ) 

(((1, 2), ((3, (4, 5)), 6)), (7, (8, ((9, (10, (11, 12))), (13, 14)))));
(((And_ful, And_hae), ((And_tri, (And_bic, And_mar)), And_hat)), (Apis_mel, (Bom_con, ((Bom_syl, (Bom_pas, (Bom_vet, Bom_mus))), (Bom_hyp, Bom_hor)))));
(((And_ful: 0.841991, And_hae: 0.841991): 0.072126, ((And_tri: 0.076523, (And_bic: 0.028541, And_mar: 0.028541): 0.047982): 0.093527, And_hat: 0.170050): 0.744067): 0.278406, (Apis_mel: 1.053510, (Bom_con: 0.332682, ((Bom_syl: 0.171771, (Bom_pas: 0.121027, (Bom_vet: 0.098141, Bom_mus: 0.098141): 0.022886): 0.050744): 0.104360, (Bom_hyp: 0.214107, Bom_hor: 0.214107): 0.062024): 0.056551): 0.720828): 0.139013);

priors: 
	mu_i ~ gammaDir(2.000, 20.000, 1.000), SD(mu_i) =  0.11180, corr(mu_i,mu_j) = 0.10000
	sigma2 ~ gammaDir(1.0000, 10.0000, 1.0000)

Initial parameters (np = 19):
  1.192523  0.914117  0.841991  0.170050  0.076523  0.028541  1.053510  0.332682  0.276131  0.171771  0.121027  0.098141  0.214107  0.030769  0.049409  0.080866  0.222073  0.009392  0.068028

lnL0 = -175554.86

Starting MCMC (np = 19) . . .
paras: 13 times, 3 mu, 3 sigma2 (& rates, kappa, alpha)

(nsteps = 98)
Current Pjump:      0.02750  0.37750  0.10750  0.03500  0.07500  0.54000  0.15000  0.12500  0.08750  0.14500  0.31250  0.77000  0.12750  0.74000  0.56500  0.84500  0.89750  0.80000  0.80000  0.65250  0.63000  0.66500  0.66500  0.77750  0.72500  0.82250  0.83250  0.72750  0.82750  0.88000  0.94250  0.86750  0.75750  0.97250  0.93500  0.89500  0.79250  0.89000  0.34750  0.61250  0.80500  0.87750  0.78750  0.95750  0.88500  0.79000  0.76750  0.67750  0.86250  0.76750  0.74000  0.67500  0.72250  0.82500  0.90250  0.85750  0.95500  0.74000  0.77750  0.67750  0.82500  0.85250  0.83000  0.83250  0.82000  0.57000  0.93250  0.93500  0.77000  0.92250  0.92000  0.49750  0.51250  0.54500  0.55750  0.50000  0.61000  0.22000  0.60500  0.92500  0.93000  0.85750  0.79250  0.62500  0.85750  0.90500  0.87750  0.68750  0.81250  0.65250  0.20250  0.67750  0.70500  0.76750  0.86750  0.88750  0.89000  0.00000
Current finetune:   0.06340  0.03225  0.09314  0.07192  0.08317  0.03318  0.02364  0.02935  0.05732  0.03521  0.05165  0.01740  0.05554  0.08539  0.09291  0.06041  0.06213  0.05790  0.04441  0.06114  0.09651  0.07284  0.07909  0.06192  0.07387  0.01803  0.03617  0.07985  0.03568  0.05981  0.02420  0.03964  0.05466  0.00371  0.02918  0.00240  0.09400  0.04101  0.09478  0.06388  0.07546  0.09202  0.01694  0.07060  0.08597  0.03209  0.07001  0.07720  0.02763  0.06130  0.05663  0.04369  0.09050  0.05372  0.04851  0.04572  0.00316  0.09720  0.06033  0.04658  0.09055  0.00961  0.07393  0.05424  0.04375  0.09251  0.00499  0.06184  0.08158  0.05814  0.07932  0.04515  0.05851  0.04068  0.06112  0.06543  0.04866  0.07778  0.05016  0.00101  0.01056  0.02315  0.04027  0.00622  0.01237  0.02632  0.00624  0.07092  0.07224  0.09039  0.06125  0.02920  0.04346  0.09375  0.00223  0.04064  0.04917  0.03672
New     finetune:   0.00538  0.04265  0.03117  0.00777  0.01932  0.07387  0.01114  0.01146  0.01556  0.01602  0.05419  0.09036  0.02213  0.38726  0.22399  0.47727  0.75076  0.34973  0.26826  0.19756  0.28835  0.24612  0.26725  0.33345  0.31449  0.12360  0.26353  0.34348  0.25206  0.61530  0.52437  0.36836  0.26786  0.16849  0.55893  0.02826  0.54585  0.46122  0.11299  0.17989  0.46828  0.92697  0.09587  2.07236  0.92391  0.18395  0.35935  0.27307  0.24713  0.31465  0.25682  0.15311  0.38132  0.37386  0.61673  0.39412  0.08772  0.44085  0.32486  0.16475  0.63013  0.07998  0.53040  0.39522  0.29555  0.22663  0.09193  1.18451  0.42373  0.93261  1.23226  0.08792  0.11944  0.09200  0.14384  0.12841  0.13589  0.05496  0.13775  0.01675  0.18773  0.19953  0.23385  0.01826  0.10666  0.34353  0.06282  0.26040  0.46737  0.29205  0.03958  0.10330  0.17070  0.48122  0.02069  0.44668  0.55293  0.00037


(nsteps = 98)
Current Pjump:      0.52000  0.14250  0.45250  0.71500  0.54500  0.17000  0.32750  0.60750  0.21750  0.33000  0.29500  0.17500  0.24750  0.10250  0.38500  0.15250  0.21250  0.52750  0.57750  0.21750  0.20000  0.14250  0.24500  0.20500  0.16000  0.20000  0.23750  0.20000  0.52750  0.17250  0.24500  0.22250  0.32500  0.17500  0.24250  0.94750  0.27000  0.27500  0.59500  0.17250  0.17500  0.23250  0.71500  0.06250  0.27250  0.39750  0.25500  0.16250  0.33500  0.22750  0.30250  0.30750  0.18000  0.20000  0.16000  0.39250  0.90000  0.17250  0.31000  0.24250  0.27500  0.90500  0.34500  0.37000  0.44250  0.20750  0.74000  0.13750  0.30250  0.37250  0.17250  0.23750  0.19000  0.29250  0.17500  0.24500  0.23250  0.42250  0.27500  0.85750  0.36750  0.37500  0.30000  0.76000  0.39250  0.22250  0.69000  0.38750  0.25250  0.13500  0.42500  0.22000  0.25500  0.29250  0.75500  0.42000  0.45250  0.00000
Current finetune:   0.00538  0.04265  0.03117  0.00777  0.01932  0.07387  0.01114  0.01146  0.01556  0.01602  0.05419  0.09036  0.02213  0.38726  0.22399  0.47727  0.75076  0.34973  0.26826  0.19756  0.28835  0.24612  0.26725  0.33345  0.31449  0.12360  0.26353  0.34348  0.25206  0.61530  0.52437  0.36836  0.26786  0.16849  0.55893  0.02826  0.54585  0.46122  0.11299  0.17989  0.46828  0.92697  0.09587  2.07236  0.92391  0.18395  0.35935  0.27307  0.24713  0.31465  0.25682  0.15311  0.38132  0.37386  0.61673  0.39412  0.08772  0.44085  0.32486  0.16475  0.63013  0.07998  0.53040  0.39522  0.29555  0.22663  0.09193  1.18451  0.42373  0.93261  1.23226  0.08792  0.11944  0.09200  0.14384  0.12841  0.13589  0.05496  0.13775  0.01675  0.18773  0.19953  0.23385  0.01826  0.10666  0.34353  0.06282  0.26040  0.46737  0.29205  0.03958  0.10330  0.17070  0.48122  0.02069  0.44668  0.55293  0.00037
New     finetune:   0.01124  0.01905  0.05266  0.03175  0.04370  0.03966  0.01235  0.03173  0.01086  0.01793  0.05314  0.05002  0.01779  0.12344  0.30383  0.22878  0.51095  0.74841  0.67328  0.13788  0.18388  0.10996  0.21245  0.21833  0.15847  0.07882  0.20243  0.21904  0.53940  0.33546  0.41684  0.26349  0.29441  0.09326  0.43931  0.67113  0.48371  0.41730  0.30023  0.09808  0.25920  0.69562  0.39182  0.40059  0.82731  0.26014  0.29864  0.13985  0.28173  0.23058  0.25932  0.15759  0.21743  0.23841  0.31078  0.54818  1.08692  0.24036  0.33758  0.12949  0.57012  1.04403  0.62671  0.50951  0.48370  0.15033  0.41694  0.51006  0.42785  1.21263  0.67183  0.06754  0.07212  0.08934  0.07962  0.10208  0.10198  0.08434  0.12463  0.14442  0.23996  0.26167  0.23385  0.09054  0.14835  0.24572  0.23286  0.35619  0.38417  0.12340  0.06124  0.07299  0.14186  0.46728  0.10028  0.68001  0.93422  0.00000


(nsteps = 98)
Current Pjump:      0.30750  0.43750  0.13750  0.19750  0.27250  0.40000  0.36500  0.30250  0.33250  0.42250  0.32000  0.37750  0.24500  0.52250  0.13750  0.33750  0.34500  0.18250  0.19500  0.41000  0.39750  0.48250  0.35500  0.30500  0.43750  0.42500  0.30500  0.36750  0.19750  0.41750  0.33000  0.27500  0.24250  0.31750  0.33250  0.18000  0.27250  0.27000  0.44000  0.42750  0.39750  0.30750  0.26750  0.58500  0.31000  0.16500  0.31250  0.47000  0.32500  0.40500  0.24500  0.29000  0.45500  0.39250  0.44500  0.26000  0.07750  0.39000  0.30500  0.29250  0.33250  0.11250  0.23000  0.31250  0.29250  0.34000  0.19000  0.47250  0.24500  0.21750  0.42500  0.35000  0.36250  0.38000  0.41250  0.43000  0.31750  0.15750  0.31750  0.27250  0.33000  0.31250  0.26000  0.51500  0.23500  0.10000  0.18500  0.17250  0.26000  0.50500  0.29250  0.38750  0.32000  0.27750  0.51250  0.21750  0.24500  0.00000
Current finetune:   0.01124  0.01905  0.05266  0.03175  0.04370  0.03966  0.01235  0.03173  0.01086  0.01793  0.05314  0.05002  0.01779  0.12344  0.30383  0.22878  0.51095  0.74841  0.67328  0.13788  0.18388  0.10996  0.21245  0.21833  0.15847  0.07882  0.20243  0.21904  0.53940  0.33546  0.41684  0.26349  0.29441  0.09326  0.43931  0.67113  0.48371  0.41730  0.30023  0.09808  0.25920  0.69562  0.39182  0.40059  0.82731  0.26014  0.29864  0.13985  0.28173  0.23058  0.25932  0.15759  0.21743  0.23841  0.31078  0.54818  1.08692  0.24036  0.33758  0.12949  0.57012  1.04403  0.62671  0.50951  0.48370  0.15033  0.41694  0.51006  0.42785  1.21263  0.67183  0.06754  0.07212  0.08934  0.07962  0.10208  0.10198  0.08434  0.12463  0.14442  0.23996  0.26167  0.23385  0.09054  0.14835  0.24572  0.23286  0.35619  0.38417  0.12340  0.06124  0.07299  0.14186  0.46728  0.10028  0.68001  0.93422  0.00000
New     finetune:   0.01157  0.03069  0.02267  0.01998  0.03913  0.05656  0.01566  0.03204  0.01227  0.02752  0.05733  0.06615  0.01414  0.26003  0.13083  0.26316  0.60373  0.43300  0.41790  0.20317  0.26003  0.20426  0.26003  0.22259  0.25525  0.12195  0.20638  0.27997  0.33938  0.50656  0.46663  0.23840  0.23140  0.09969  0.49629  0.38267  0.43313  0.36980  0.48745  0.15297  0.36656  0.71601  0.34359  1.03016  0.85970  0.13537  0.31328  0.24974  0.30965  0.33425  0.20615  0.15152  0.37029  0.33160  0.51271  0.46557  0.26098  0.33153  0.34416  0.12575  0.64406  0.36591  0.46477  0.53449  0.46970  0.17449  0.25174  0.91810  0.34012  0.84628  1.03945  0.08123  0.09060  0.11916  0.11828  0.16050  0.10901  0.04181  0.13323  0.12932  0.26862  0.27450  0.19861  0.18626  0.11264  0.07638  0.13668  0.19419  0.32628  0.24602  0.05947  0.09984  0.15306  0.42716  0.20469  0.47457  0.74265  0.00000


(nsteps = 98)
Current Pjump:      0.31750  0.20500  0.40000  0.33250  0.21000  0.25250  0.32500  0.30250  0.31000  0.35250  0.26250  0.27750  0.21000  0.14500  0.51000  0.29500  0.28000  0.44500  0.46750  0.22750  0.25750  0.27500  0.25500  0.31500  0.23500  0.30250  0.36250  0.22750  0.37000  0.22500  0.22750  0.35000  0.30000  0.31500  0.29000  0.37000  0.26000  0.31500  0.20750  0.28000  0.22000  0.24500  0.27750  0.20750  0.29250  0.54500  0.28250  0.25500  0.28750  0.28500  0.38750  0.33000  0.23250  0.28750  0.30500  0.33250  0.58500  0.29000  0.31000  0.31250  0.27000  0.56000  0.35000  0.25750  0.27500  0.32000  0.43000  0.25250  0.32000  0.29500  0.27250  0.30000  0.28750  0.22000  0.30250  0.18250  0.29500  0.49500  0.30000  0.34000  0.20500  0.23750  0.33750  0.16750  0.32750  0.52250  0.46000  0.50000  0.35000  0.24500  0.34250  0.25500  0.27750  0.31500  0.27250  0.38500  0.38500  0.00000
Current finetune:   0.01157  0.03069  0.02267  0.01998  0.03913  0.05656  0.01566  0.03204  0.01227  0.02752  0.05733  0.06615  0.01414  0.26003  0.13083  0.26316  0.60373  0.43300  0.41790  0.20317  0.26003  0.20426  0.26003  0.22259  0.25525  0.12195  0.20638  0.27997  0.33938  0.50656  0.46663  0.23840  0.23140  0.09969  0.49629  0.38267  0.43313  0.36980  0.48745  0.15297  0.36656  0.71601  0.34359  1.03016  0.85970  0.13537  0.31328  0.24974  0.30965  0.33425  0.20615  0.15152  0.37029  0.33160  0.51271  0.46557  0.26098  0.33153  0.34416  0.12575  0.64406  0.36591  0.46477  0.53449  0.46970  0.17449  0.25174  0.91810  0.34012  0.84628  1.03945  0.08123  0.09060  0.11916  0.11828  0.16050  0.10901  0.04181  0.13323  0.12932  0.26862  0.27450  0.19861  0.18626  0.11264  0.07638  0.13668  0.19419  0.32628  0.24602  0.05947  0.09984  0.15306  0.42716  0.20469  0.47457  0.74265  0.00000
New     finetune:   0.01237  0.02010  0.03233  0.02257  0.02629  0.04649  0.01721  0.03235  0.01275  0.03339  0.04922  0.06047  0.00950  0.11829  0.26497  0.25807  0.55757  0.71434  0.74044  0.14889  0.21847  0.18481  0.21610  0.23572  0.19380  0.12313  0.25928  0.20517  0.43753  0.36678  0.34196  0.28672  0.23140  0.10557  0.47717  0.49334  0.36786  0.39160  0.32335  0.14128  0.25900  0.56918  0.31409  0.68336  0.83481  0.30617  0.29228  0.20755  0.29477  0.31501  0.28198  0.16962  0.27788  0.31566  0.52270  0.52595  0.67114  0.31876  0.35764  0.13191  0.57074  0.86808  0.55898  0.44906  0.42497  0.18827  0.39583  0.75467  0.36697  0.82992  0.93078  0.08123  0.08625  0.08420  0.11943  0.09286  0.10690  0.08078  0.13323  0.15010  0.17589  0.21085  0.22846  0.09847  0.12494  0.16090  0.23649  0.38113  0.39241  0.19557  0.06964  0.08297  0.13992  0.45235  0.18329  0.64373  1.00737  0.00000

  0% 0.47 0.41 0.32 0.27 0.40  1.229 0.238 0.191 0.177 0.145 0.098 - 0.187 0.224 -155959.8  0:38

(nsteps = 98)
Current Pjump:      0.47500  0.41250  0.31750  0.26750  0.39750  0.36500  0.47500  0.36250  0.27750  0.30750  0.28500  0.26500  0.35750  0.45250  0.14750  0.24000  0.35500  0.20500  0.21500  0.37000  0.32750  0.30750  0.34500  0.29750  0.33500  0.24250  0.24750  0.41250  0.20750  0.34500  0.37750  0.27000  0.35000  0.27750  0.31750  0.23000  0.41000  0.27250  0.30000  0.23500  0.31500  0.31000  0.32750  0.36250  0.23750  0.11250  0.35750  0.27250  0.27250  0.27500  0.28000  0.23500  0.35500  0.28500  0.20750  0.19500  0.14750  0.32250  0.30000  0.28000  0.30750  0.21500  0.26250  0.33250  0.29250  0.22000  0.22500  0.29750  0.31500  0.33750  0.26750  0.28500  0.30750  0.33500  0.25750  0.39500  0.26250  0.17000  0.29250  0.26250  0.36250  0.33250  0.27250  0.48000  0.29000  0.01000  0.24000  0.21500  0.21750  0.35250  0.76000  0.32250  0.34500  0.26250  0.25500  0.24500  0.19000  0.00000
Current finetune:   0.01237  0.02010  0.03233  0.02257  0.02629  0.04649  0.01721  0.03235  0.01275  0.03339  0.04922  0.06047  0.00950  0.11829  0.26497  0.25807  0.55757  0.71434  0.74044  0.14889  0.21847  0.18481  0.21610  0.23572  0.19380  0.12313  0.25928  0.20517  0.43753  0.36678  0.34196  0.28672  0.23140  0.10557  0.47717  0.49334  0.36786  0.39160  0.32335  0.14128  0.25900  0.56918  0.31409  0.68336  0.83481  0.30617  0.29228  0.20755  0.29477  0.31501  0.28198  0.16962  0.27788  0.31566  0.52270  0.52595  0.67114  0.31876  0.35764  0.13191  0.57074  0.86808  0.55898  0.44906  0.42497  0.18827  0.39583  0.75467  0.36697  0.82992  0.93078  0.08123  0.08625  0.08420  0.11943  0.09286  0.10690  0.08078  0.13323  0.15010  0.17589  0.21085  0.22846  0.09847  0.12494  0.16090  0.23649  0.38113  0.39241  0.19557  0.06964  0.08297  0.13992  0.45235  0.18329  0.64373  1.00737  0.00000
New     finetune:   0.02244  0.02985  0.03456  0.01979  0.03718  0.05891  0.03122  0.04065  0.01165  0.03437  0.04638  0.05247  0.01173  0.19986  0.12269  0.20054  0.68246  0.46773  0.51032  0.19194  0.24234  0.19023  0.25534  0.23343  0.22093  0.09678  0.20844  0.30481  0.29023  0.43338  0.45225  0.25407  0.27830  0.09650  0.51006  0.36587  0.54207  0.35066  0.32335  0.10727  0.27428  0.59146  0.34840  0.85854  0.64126  0.10731  0.36089  0.18585  0.26395  0.28501  0.26042  0.12879  0.34012  0.29749  0.34674  0.32645  0.31076  0.34713  0.35764  0.12182  0.58746  0.59830  0.47986  0.50730  0.41267  0.13303  0.28660  0.74735  0.38861  0.95466  0.81619  0.07655  0.08877  0.09598  0.10034  0.13024  0.09177  0.04337  0.12937  0.12886  0.22097  0.23820  0.20457  0.18147  0.12013  0.00496  0.18376  0.26268  0.27386  0.23729  0.34522  0.09036  0.16533  0.38833  0.15232  0.51173  0.60822  0.00000

  1% 0.23 0.25 0.29 0.35 0.25  1.203 0.238 0.189 0.177 0.146 0.103 - 0.206 0.232 -155959.5  2% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.190 0.177 0.147 0.103 - 0.206 0.232 -155959.5  3% 0.23 0.25 0.29 0.35 0.25  1.195 0.239 0.190 0.177 0.147 0.103 - 0.206 0.232 -155959.5  4% 0.23 0.25 0.29 0.35 0.25  1.196 0.240 0.191 0.177 0.147 0.103 - 0.206 0.231 -155959.5  5% 0.23 0.25 0.29 0.35 0.25  1.193 0.240 0.191 0.177 0.147 0.103 - 0.206 0.232 -155959.5 57:56
  6% 0.23 0.25 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.232 -155959.5  7% 0.23 0.25 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.232 -155959.5  8% 0.23 0.25 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.147 0.103 - 0.205 0.232 -155959.5  9% 0.23 0.25 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.147 0.103 - 0.206 0.232 -155959.5 10% 0.23 0.25 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.206 0.232 -155959.5 1:55:22
 11% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.233 -155959.5 12% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.206 0.233 -155959.6 13% 0.23 0.25 0.29 0.35 0.25  1.189 0.240 0.191 0.177 0.146 0.103 - 0.206 0.233 -155959.6 14% 0.23 0.25 0.29 0.35 0.25  1.188 0.240 0.191 0.177 0.147 0.103 - 0.206 0.233 -155959.6 15% 0.23 0.24 0.29 0.35 0.25  1.189 0.240 0.191 0.177 0.146 0.103 - 0.206 0.233 -155959.5 2:52:52
 16% 0.23 0.25 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.147 0.103 - 0.206 0.233 -155959.5 17% 0.23 0.25 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.206 0.233 -155959.5 18% 0.23 0.24 0.29 0.35 0.25  1.193 0.240 0.191 0.177 0.147 0.103 - 0.206 0.234 -155959.5 19% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.234 -155959.5 20% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.233 -155959.5 3:50:06
 21% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.233 -155959.5 22% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.234 -155959.5 23% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 24% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.205 0.233 -155959.5 25% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.233 -155959.5 4:47:14
 26% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.147 0.103 - 0.205 0.233 -155959.5 27% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 28% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 29% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 30% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 5:44:29
 31% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 32% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 33% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 34% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 35% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 6:41:46
 36% 0.23 0.24 0.29 0.35 0.25  1.193 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 37% 0.23 0.24 0.29 0.35 0.25  1.193 0.239 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 38% 0.23 0.24 0.29 0.35 0.25  1.193 0.240 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 39% 0.23 0.24 0.29 0.35 0.25  1.193 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 40% 0.23 0.24 0.29 0.35 0.25  1.193 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 7:39:03
 41% 0.23 0.24 0.29 0.35 0.25  1.194 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 42% 0.23 0.24 0.29 0.35 0.25  1.194 0.240 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 43% 0.23 0.24 0.29 0.35 0.25  1.194 0.240 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 44% 0.23 0.24 0.29 0.35 0.25  1.193 0.240 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 45% 0.23 0.24 0.29 0.35 0.25  1.193 0.239 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 8:36:25
 46% 0.23 0.24 0.29 0.35 0.25  1.193 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 47% 0.23 0.24 0.29 0.35 0.25  1.193 0.239 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 48% 0.23 0.24 0.29 0.35 0.25  1.193 0.239 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 49% 0.23 0.24 0.29 0.35 0.25  1.193 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 50% 0.23 0.24 0.29 0.35 0.25  1.193 0.239 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 9:33:49
 51% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 52% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 53% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 54% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 55% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 10:31:18
 56% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 57% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 58% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 59% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 60% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 11:28:01
 61% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 62% 0.23 0.24 0.29 0.35 0.25  1.192 0.240 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 63% 0.23 0.24 0.29 0.35 0.25  1.191 0.240 0.191 0.177 0.146 0.103 - 0.206 0.234 -155959.5 64% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 65% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 12:24:48
 66% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 67% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 68% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 69% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 70% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 13:21:32
 71% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 72% 0.23 0.24 0.29 0.35 0.25  1.192 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 73% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 74% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 75% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 14:18:23
 76% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 77% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 78% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.190 0.177 0.146 0.103 - 0.205 0.234 -155959.5 79% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.190 0.177 0.146 0.103 - 0.205 0.234 -155959.5 80% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.190 0.177 0.146 0.103 - 0.205 0.234 -155959.5 15:15:03
 81% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.190 0.177 0.146 0.103 - 0.205 0.234 -155959.5 82% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.190 0.177 0.146 0.103 - 0.205 0.234 -155959.5 83% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.190 0.177 0.146 0.103 - 0.205 0.234 -155959.5 84% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 85% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 16:11:49
 86% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 87% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 88% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 89% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 90% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 17:08:31
 91% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 92% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 93% 0.23 0.24 0.29 0.35 0.25  1.191 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 94% 0.23 0.24 0.29 0.35 0.25  1.190 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 95% 0.23 0.24 0.29 0.35 0.25  1.190 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 18:05:19
 96% 0.23 0.24 0.29 0.35 0.25  1.190 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 97% 0.23 0.24 0.29 0.35 0.25  1.190 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 98% 0.23 0.24 0.29 0.35 0.25  1.190 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 99% 0.23 0.24 0.29 0.35 0.25  1.190 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5100% 0.23 0.24 0.29 0.35 0.25  1.190 0.239 0.191 0.177 0.146 0.103 - 0.205 0.234 -155959.5 19:01:54

Time used: 19:01:54
Summarizing MCMC samples . ..

Data file has a header line.
60001 records, 21 variables
Collecting mean, median, min, max, percentiles, etc.

			    21/    21 done  19:01:55


Posterior means (95% Equal-tail CI) (95% HPD CI) HPD-CI-width

t_n15          1.1904 ( 1.0561,  1.3183) ( 1.0561,  1.3183)  0.2622  (Jnode 26)
t_n16          0.2394 ( 0.2087,  0.2774) ( 0.2069,  0.2752)  0.0684  (Jnode 25)
t_n17          0.1906 ( 0.1579,  0.2272) ( 0.1563,  0.2252)  0.0689  (Jnode 24)
t_n18          0.1770 ( 0.1677,  0.1811) ( 0.1695,  0.1819)  0.0124  (Jnode 23)
t_n19          0.1464 ( 0.1310,  0.1589) ( 0.1324,  0.1600)  0.0276  (Jnode 22)
t_n20          0.1032 ( 0.0834,  0.1216) ( 0.0840,  0.1221)  0.0380  (Jnode 21)
t_n21          0.9541 ( 0.8874,  1.0989) ( 0.8790,  1.0768)  0.1977  (Jnode 20)
t_n22          0.3063 ( 0.2657,  0.3613) ( 0.2629,  0.3566)  0.0937  (Jnode 19)
t_n23          0.2073 ( 0.2016,  0.2183) ( 0.2008,  0.2164)  0.0155  (Jnode 18)
t_n24          0.1894 ( 0.1749,  0.2033) ( 0.1758,  0.2041)  0.0283  (Jnode 17)
t_n25          0.0526 ( 0.0375,  0.0719) ( 0.0360,  0.0699)  0.0339  (Jnode 16)
t_n26          0.0474 ( 0.0327,  0.0663) ( 0.0316,  0.0648)  0.0332  (Jnode 15)
t_n27          0.2034 ( 0.1990,  0.2139) ( 0.1983,  0.2121)  0.0137  (Jnode 14)
mu1            0.0499 ( 0.0410,  0.0614) ( 0.0401,  0.0602)  0.0201
mu2            0.0328 ( 0.0266,  0.0412) ( 0.0261,  0.0403)  0.0142
mu3            0.2316 ( 0.1869,  0.2891) ( 0.1820,  0.2828)  0.1008
sigma2_1       0.1789 ( 0.0891,  0.3319) ( 0.0767,  0.3042)  0.2275
sigma2_2       0.2054 ( 0.1024,  0.3792) ( 0.0877,  0.3485)  0.2608
sigma2_3       0.2339 ( 0.1276,  0.4078) ( 0.1145,  0.3802)  0.2657
lnL        -155959.5547 (-155972.1660, -155948.7840) (-155971.3780, -155948.1910) 23.1870

mean	1.1904	0.2394	0.1906	0.1770	0.1464	0.1032	0.9541	0.3063	0.2073	0.1894	0.0526	0.0474	0.2034	0.0499	0.0328	0.2316	0.1789	0.2054	0.2339	-155959.5547
Eff 	0.0271	0.2461	0.2586	0.7415	0.6271	0.4909	0.1924	0.3989	0.4196	0.6664	0.1541	0.1552	0.4458	0.6941	0.6381	0.6092	0.7240	0.8388	0.6104	0.9746
time prior: Birth-Death-Sampling
rate prior: Log-Normal

Time used: 19:01:55
