MCMCTREE in paml version 4.9j, February 2020

Reading options from mcmctree.ctl..
finetune is deprecated now.
Reading master tree.
(((((((Bom_mus, Bom_vet), Bom_pas), Bom_syl), Bom_hor), Bom_hyp), Bom_con), Apis_mel);

Reading sequence data..  3 loci


*** Locus 1 ***
ns = 8  	ls = 89754
Reading sequences, sequential format..
Reading seq # 1: Apis_mel       Reading seq # 2: Bom_con       Reading seq # 3: Bom_hor       Reading seq # 4: Bom_hyp       Reading seq # 5: Bom_mus       Reading seq # 6: Bom_pas       Reading seq # 7: Bom_syl       Reading seq # 8: Bom_vet       
Sequences read..
Counting site patterns..  0:00
Compressing,    429 patterns at  10000 /  89754 sites (11.1%),  0:00Compressing,    763 patterns at  20000 /  89754 sites (22.3%),  0:00Compressing,    991 patterns at  30000 /  89754 sites (33.4%),  0:00Compressing,   1108 patterns at  40000 /  89754 sites (44.6%),  0:00Compressing,   1271 patterns at  50000 /  89754 sites (55.7%),  0:00Compressing,   1400 patterns at  60000 /  89754 sites (66.8%),  0:00Compressing,   1446 patterns at  70000 /  89754 sites (78.0%),  0:00Compressing,   1539 patterns at  80000 /  89754 sites (89.1%),  0:00Compressing,   1573 patterns at  89754 /  89754 sites (100.0%),  0:00
Collecting fpatt[] & pose[],   1573 patterns at  10000 /  89754 sites (11.1%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  20000 /  89754 sites (22.3%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  30000 /  89754 sites (33.4%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  40000 /  89754 sites (44.6%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  50000 /  89754 sites (55.7%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  60000 /  89754 sites (66.8%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  70000 /  89754 sites (78.0%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  80000 /  89754 sites (89.1%),  0:00Collecting fpatt[] & pose[],   1573 patterns at  89754 /  89754 sites (100.0%),  0:00
Counting frequencies..
1573 patterns, messy


*** Locus 2 ***
ns = 8  	ls = 89854
Reading sequences, sequential format..
Reading seq # 1: Apis_mel       Reading seq # 2: Bom_con       Reading seq # 3: Bom_hor       Reading seq # 4: Bom_hyp       Reading seq # 5: Bom_mus       Reading seq # 6: Bom_pas       Reading seq # 7: Bom_syl       Reading seq # 8: Bom_vet       
Sequences read..
Counting site patterns..  0:00
Compressing,    364 patterns at  10000 /  89854 sites (11.1%),  0:00Compressing,    692 patterns at  20000 /  89854 sites (22.3%),  0:00Compressing,    920 patterns at  30000 /  89854 sites (33.4%),  0:00Compressing,   1015 patterns at  40000 /  89854 sites (44.5%),  0:00Compressing,   1148 patterns at  50000 /  89854 sites (55.6%),  0:00Compressing,   1258 patterns at  60000 /  89854 sites (66.8%),  0:00Compressing,   1290 patterns at  70000 /  89854 sites (77.9%),  0:00Compressing,   1370 patterns at  80000 /  89854 sites (89.0%),  0:00Compressing,   1395 patterns at  89854 /  89854 sites (100.0%),  0:00
Collecting fpatt[] & pose[],   1395 patterns at  10000 /  89854 sites (11.1%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  20000 /  89854 sites (22.3%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  30000 /  89854 sites (33.4%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  40000 /  89854 sites (44.5%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  50000 /  89854 sites (55.6%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  60000 /  89854 sites (66.8%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  70000 /  89854 sites (77.9%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  80000 /  89854 sites (89.0%),  0:00Collecting fpatt[] & pose[],   1395 patterns at  89854 /  89854 sites (100.0%),  0:00
Counting frequencies..
1395 patterns, messy


*** Locus 3 ***
ns = 8  	ls = 89754
Reading sequences, sequential format..
Reading seq # 1: Apis_mel       Reading seq # 2: Bom_con       Reading seq # 3: Bom_hor       Reading seq # 4: Bom_hyp       Reading seq # 5: Bom_mus       Reading seq # 6: Bom_pas       Reading seq # 7: Bom_syl       Reading seq # 8: Bom_vet       
Sequences read..
Counting site patterns..  0:00
Compressing,    642 patterns at  10000 /  89754 sites (11.1%),  0:00Compressing,   1087 patterns at  20000 /  89754 sites (22.3%),  0:00Compressing,   1442 patterns at  30000 /  89754 sites (33.4%),  0:00Compressing,   1595 patterns at  40000 /  89754 sites (44.6%),  0:00Compressing,   1832 patterns at  50000 /  89754 sites (55.7%),  0:00Compressing,   2082 patterns at  60000 /  89754 sites (66.8%),  0:00Compressing,   2201 patterns at  70000 /  89754 sites (78.0%),  0:00Compressing,   2355 patterns at  80000 /  89754 sites (89.1%),  0:00Compressing,   2417 patterns at  89754 /  89754 sites (100.0%),  0:00
Collecting fpatt[] & pose[],   2417 patterns at  10000 /  89754 sites (11.1%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  20000 /  89754 sites (22.3%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  30000 /  89754 sites (33.4%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  40000 /  89754 sites (44.6%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  50000 /  89754 sites (55.7%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  60000 /  89754 sites (66.8%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  70000 /  89754 sites (78.0%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  80000 /  89754 sites (89.1%),  0:00Collecting fpatt[] & pose[],   2417 patterns at  89754 /  89754 sites (100.0%),  0:00
Counting frequencies..
2417 patterns, messy


Fossil calibration information used.
Node   9:   B (  0.2500,  0.4000,  0.0250,  0.0250 )
Node  10:   B (  0.2500,  0.4000,  0.0250,  0.0250 )
360 bytes for rates.

Reading branch lengths, Gradient & Hessian from in.BV.
Locus 1: 8 speciesLocus 2: 8 speciesLocus 3: 8 species
200000 burnin, sampled every 2000, 40000 samples
Approximating posterior
(Settings: cleandata=0  print=1  saveconP=0)

getting initial values to start MCMC.

*** min-age round  1: from nodes  10 (  0.32844) to   9,   2 nodes 
************
Species tree
ns = 8  nnode = 15
 father   node  name              time     sons          fossil
     15      1  Bom_mus           0.00000
     15      2  Bom_vet           0.00000
     14      3  Bom_pas           0.00000
     13      4  Bom_syl           0.00000
     12      5  Bom_hor           0.00000
     11      6  Bom_hyp           0.00000
     10      7  Bom_con           0.00000
      9      8  Apis_mel          0.00000
      0      9                    0.37634  (10  8)  B ( 0.2500, 0.4000, 0.0250, 0.0250 ) 
      9     10                    0.32844  (11  7)  B ( 0.2500, 0.4000, 0.0250, 0.0250 ) 
     10     11                    0.28495  (12  6)
     11     12                    0.20592  (13  5)
     12     13                    0.20179  (14  4)
     13     14                    0.10766  (15  3)
     14     15                    0.00785  ( 1  2)

(((((((1, 2), 3), 4), 5), 6), 7), 8);
(((((((Bom_mus, Bom_vet), Bom_pas), Bom_syl), Bom_hor), Bom_hyp), Bom_con), Apis_mel);
(((((((Bom_mus: 0.007849, Bom_vet: 0.007849): 0.099815, Bom_pas: 0.107664): 0.094124, Bom_syl: 0.201788): 0.004134, Bom_hor: 0.205922): 0.079024, Bom_hyp: 0.284945): 0.043493, Bom_con: 0.328439): 0.047904, Apis_mel: 0.376343);

priors: 
	mu_i ~ gammaDir(2.000, 20.000, 1.000), SD(mu_i) =  0.11180, corr(mu_i,mu_j) = 0.10000
	sigma2 ~ gammaDir(1.0000, 10.0000, 1.0000)

Initial parameters (np = 13):
  0.376343  0.328439  0.284945  0.205922  0.201788  0.107664  0.007849  0.023178  0.132564  0.092619  0.055930  0.040637  0.016767

lnL0 = -43867.56

Starting MCMC (np = 13) . . .
paras: 7 times, 3 mu, 3 sigma2 (& rates, kappa, alpha)

(nsteps = 56)
Current Pjump:      0.00425  0.01252  0.90375  0.02410  0.70032  0.12713  0.70782  0.98118  0.95528  0.75230  0.93483  0.94998  0.94022  0.70948  0.96353  0.66467  0.35713  0.67682  0.70155  0.76410  0.12120  0.84622  0.35175  0.83083  0.96448  0.82017  0.84592  0.79575  0.95787  0.78480  0.95460  0.85045  0.97402  0.56430  0.53458  0.79185  0.58778  0.80583  0.87155  0.73745  0.86193  0.27910  0.54925  0.36005  0.13227  0.51730  0.78987  0.59827  0.03700  0.95205  0.31483  0.60710  0.92815  0.71262  0.96875  0.00000
Current finetune:   0.08418  0.05840  0.00114  0.03419  0.00451  0.05664  0.01430  0.00420  0.01231  0.08267  0.05723  0.04523  0.04957  0.06508  0.00762  0.06241  0.07668  0.03452  0.03826  0.02181  0.05759  0.03162  0.10077  0.05566  0.01056  0.02308  0.04605  0.04981  0.01033  0.04305  0.00470  0.01834  0.00276  0.05199  0.02601  0.04473  0.06770  0.08019  0.04883  0.04449  0.04123  0.09816  0.05288  0.07889  0.08312  0.03103  0.01374  0.02433  0.05033  0.00923  0.06024  0.07733  0.01276  0.02254  0.00745  0.04949
New     finetune:   0.00110  0.00226  0.01473  0.00254  0.01740  0.02250  0.05681  0.27848  0.34329  0.39572  1.09326  1.12732  1.03314  0.26018  0.26080  0.21063  0.09456  0.12181  0.14826  0.11020  0.02178  0.25193  0.12195  0.40132  0.37093  0.15608  0.36611  0.29416  0.30608  0.24035  0.12907  0.15036  0.13275  0.12505  0.05691  0.25883  0.17567  0.49990  0.46855  0.19960  0.36724  0.09032  0.12122  0.09828  0.03439  0.06431  0.07869  0.06536  0.00575  0.24010  0.06375  0.21386  0.22091  0.09125  0.29748  0.00049


(nsteps = 56)
Current Pjump:      0.90953  0.87363  0.22008  0.77125  0.19572  0.46623  0.17233  0.26415  0.17650  0.16652  0.17170  0.16935  0.18160  0.17847  0.15127  0.18587  0.26772  0.18460  0.18442  0.17450  0.49625  0.24483  0.26652  0.16500  0.17655  0.17300  0.16712  0.17035  0.16043  0.16850  0.20380  0.16485  0.27350  0.20060  0.20573  0.25740  0.19420  0.16952  0.18002  0.16950  0.19072  0.31307  0.19195  0.26310  0.47942  0.20793  0.17310  0.19625  0.74275  0.19200  0.28710  0.19352  0.17815  0.17722  0.16523  0.00000
Current finetune:   0.00110  0.00226  0.01473  0.00254  0.01740  0.02250  0.05681  0.27848  0.34329  0.39572  1.09326  1.12732  1.03314  0.26018  0.26080  0.21063  0.09456  0.12181  0.14826  0.11020  0.02178  0.25193  0.12195  0.40132  0.37093  0.15608  0.36611  0.29416  0.30608  0.24035  0.12907  0.15036  0.13275  0.12505  0.05691  0.25883  0.17567  0.49990  0.46855  0.19960  0.36724  0.09032  0.12122  0.09828  0.03439  0.06431  0.07869  0.06536  0.00575  0.24010  0.06375  0.21386  0.22091  0.09125  0.29748  0.00049
New     finetune:   0.01513  0.02200  0.01042  0.01328  0.01084  0.03970  0.03094  0.24075  0.19173  0.20792  0.59315  0.60284  0.59462  0.14703  0.12397  0.12425  0.08299  0.07133  0.08674  0.06082  0.04225  0.20011  0.10650  0.20884  0.20723  0.08536  0.19309  0.15828  0.15467  0.12785  0.08398  0.07817  0.11936  0.08000  0.03740  0.21737  0.10856  0.26761  0.26720  0.10684  0.22263  0.09496  0.07399  0.08458  0.06327  0.04275  0.04306  0.04085  0.02638  0.14659  0.06059  0.13167  0.12460  0.05118  0.15502  0.00000


(nsteps = 56)
Current Pjump:      0.16118  0.15937  0.35740  0.18448  0.38135  0.23488  0.41100  0.32355  0.39713  0.42698  0.42262  0.42195  0.40027  0.41210  0.45467  0.39857  0.32825  0.40572  0.40725  0.42445  0.21950  0.31900  0.32258  0.43378  0.41523  0.42525  0.42980  0.43133  0.44040  0.42857  0.38000  0.43445  0.32115  0.39087  0.36812  0.34168  0.39170  0.42593  0.41035  0.42600  0.39527  0.29615  0.40737  0.32792  0.22368  0.38462  0.41877  0.39503  0.20350  0.29955  0.31233  0.39155  0.41557  0.41690  0.43360  0.00000
Current finetune:   0.01513  0.02200  0.01042  0.01328  0.01084  0.03970  0.03094  0.24075  0.19173  0.20792  0.59315  0.60284  0.59462  0.14703  0.12397  0.12425  0.08299  0.07133  0.08674  0.06082  0.04225  0.20011  0.10650  0.20884  0.20723  0.08536  0.19309  0.15828  0.15467  0.12785  0.08398  0.07817  0.11936  0.08000  0.03740  0.21737  0.10856  0.26761  0.26720  0.10684  0.22263  0.09496  0.07399  0.08458  0.06327  0.04275  0.04306  0.04085  0.02638  0.14659  0.06059  0.13167  0.12460  0.05118  0.15502  0.00000
New     finetune:   0.00768  0.01104  0.01286  0.00777  0.01452  0.03013  0.04574  0.26320  0.27080  0.32374  0.91069  0.92356  0.84864  0.21815  0.21091  0.17633  0.09232  0.10365  0.12667  0.09393  0.02978  0.21511  0.11601  0.33238  0.31062  0.13217  0.30340  0.24993  0.25144  0.20011  0.11202  0.12468  0.12934  0.11067  0.04791  0.25381  0.15060  0.41529  0.39419  0.16583  0.31252  0.09354  0.10809  0.09397  0.04551  0.05792  0.06529  0.05729  0.01714  0.14633  0.06352  0.18257  0.18698  0.07714  0.24659  0.00000


(nsteps = 56)
Current Pjump:      0.44445  0.46495  0.28845  0.41323  0.27158  0.34220  0.24680  0.27215  0.24808  0.22728  0.24017  0.23427  0.25507  0.24030  0.22545  0.24848  0.28665  0.24085  0.24260  0.23582  0.36295  0.29042  0.28868  0.23442  0.24450  0.23645  0.23905  0.23270  0.22925  0.23692  0.26185  0.23380  0.28555  0.25062  0.27248  0.24855  0.25812  0.23410  0.23760  0.23475  0.25040  0.29785  0.24210  0.28155  0.36615  0.25168  0.24585  0.24785  0.36350  0.31163  0.29248  0.25208  0.23772  0.23738  0.23380  0.00000
Current finetune:   0.00768  0.01104  0.01286  0.00777  0.01452  0.03013  0.04574  0.26320  0.27080  0.32374  0.91069  0.92356  0.84864  0.21815  0.21091  0.17633  0.09232  0.10365  0.12667  0.09393  0.02978  0.21511  0.11601  0.33238  0.31062  0.13217  0.30340  0.24993  0.25144  0.20011  0.11202  0.12468  0.12934  0.11067  0.04791  0.25381  0.15060  0.41529  0.39419  0.16583  0.31252  0.09354  0.10809  0.09397  0.04551  0.05792  0.06529  0.05729  0.01714  0.14633  0.06352  0.18257  0.18698  0.07714  0.24659  0.00000
New     finetune:   0.01265  0.01941  0.01228  0.01157  0.01296  0.03525  0.03666  0.23534  0.21827  0.23699  0.70822  0.69887  0.70550  0.16975  0.15304  0.14238  0.08758  0.08086  0.09960  0.07159  0.03747  0.20717  0.11095  0.25169  0.24636  0.10103  0.23473  0.18773  0.18581  0.15330  0.09589  0.09414  0.12216  0.09022  0.04290  0.20501  0.12687  0.31399  0.30294  0.12577  0.25452  0.09276  0.08480  0.08733  0.05791  0.04744  0.05210  0.04613  0.02160  0.15300  0.06167  0.14978  0.14377  0.05922  0.18618  0.00000

  0% 0.23 0.21 0.30 0.24 0.31  0.393 0.254 0.148 0.132 0.118 0.046 - 0.169 0.218 -19.3  0:08

(nsteps = 56)
Current Pjump:      0.23358  0.21253  0.29892  0.24105  0.30658  0.27528  0.34072  0.32913  0.34917  0.36095  0.34512  0.35882  0.33578  0.34497  0.36270  0.33460  0.29957  0.34808  0.34245  0.35190  0.26090  0.32262  0.30775  0.35815  0.34167  0.35570  0.34635  0.35540  0.35645  0.34645  0.32423  0.35755  0.30995  0.33543  0.31477  0.34638  0.32830  0.35442  0.35137  0.35363  0.33635  0.30240  0.34680  0.31027  0.25815  0.33825  0.34188  0.34097  0.27035  0.30302  0.30388  0.33550  0.34852  0.35253  0.35170  0.00000
Current finetune:   0.01265  0.01941  0.01228  0.01157  0.01296  0.03525  0.03666  0.23534  0.21827  0.23699  0.70822  0.69887  0.70550  0.16975  0.15304  0.14238  0.08758  0.08086  0.09960  0.07159  0.03747  0.20717  0.11095  0.25169  0.24636  0.10103  0.23473  0.18773  0.18581  0.15330  0.09589  0.09414  0.12216  0.09022  0.04290  0.20501  0.12687  0.31399  0.30294  0.12577  0.25452  0.09276  0.08480  0.08733  0.05791  0.04744  0.05210  0.04613  0.02160  0.15300  0.06167  0.14978  0.14377  0.05922  0.18618  0.00000
New     finetune:   0.00954  0.01321  0.01223  0.00904  0.01329  0.03193  0.04266  0.26261  0.26174  0.29615  0.83720  0.86690  0.80651  0.20055  0.19240  0.16207  0.08744  0.09659  0.11662  0.08668  0.03195  0.22572  0.11431  0.31147  0.28767  0.12397  0.27869  0.23010  0.22858  0.18208  0.10510  0.11626  0.12692  0.10300  0.04539  0.24342  0.14115  0.38355  0.36611  0.15320  0.29156  0.09363  0.10084  0.09085  0.04879  0.05471  0.06088  0.05373  0.01917  0.15480  0.06261  0.17106  0.17202  0.07186  0.22526  0.00000

  1% 0.35 0.39 0.31 0.35 0.31  0.392 0.252 0.140 0.125 0.111 0.044 - 0.169 0.210 -19.3  2% 0.34 0.38 0.31 0.34 0.30  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3  3% 0.34 0.38 0.31 0.34 0.30  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3  4% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.213 -19.3  5% 0.35 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.213 -19.3  2:53
  6% 0.35 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.112 0.044 - 0.169 0.213 -19.3  7% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3  8% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3  9% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.213 -19.3 10% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.213 -19.3  5:37
 11% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.213 -19.3 12% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3 13% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3 14% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3 15% 0.34 0.38 0.31 0.35 0.30  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3  8:20
 16% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3 17% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.214 -19.3 18% 0.34 0.38 0.31 0.35 0.30  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.215 -19.3 19% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.215 -19.3 20% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.215 -19.3 11:03
 21% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.215 -19.3 22% 0.34 0.38 0.31 0.35 0.30  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.215 -19.3 23% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.215 -19.3 24% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.045 - 0.169 0.215 -19.3 25% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 13:46
 26% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 27% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 28% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 29% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 30% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 16:29
 31% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 32% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 33% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 34% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 35% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 19:12
 36% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 37% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 38% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 39% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 40% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 21:55
 41% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 42% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 43% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 44% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 45% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 24:38
 46% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 47% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 48% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 49% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 50% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 27:22
 51% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 52% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.127 0.113 0.044 - 0.169 0.214 -19.3 53% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 54% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 55% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 30:05
 56% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 57% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 58% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 59% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.215 -19.3 60% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 32:48
 61% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 62% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 63% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 64% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 65% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 35:31
 66% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 67% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 68% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 69% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 70% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 38:14
 71% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 72% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 73% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 74% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 75% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 40:57
 76% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 77% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 78% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 79% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 80% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 43:40
 81% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 82% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 83% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 84% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 85% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 46:23
 86% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 87% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 88% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 89% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.142 0.126 0.113 0.044 - 0.169 0.214 -19.3 90% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 49:06
 91% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 92% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 93% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 94% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 95% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 51:49
 96% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 97% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 98% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 99% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3100% 0.34 0.38 0.31 0.35 0.31  0.392 0.253 0.141 0.126 0.113 0.044 - 0.169 0.214 -19.3 54:32

Time used: 54:32
Summarizing MCMC samples . ..

Data file has a header line.
40001 records, 15 variables
Collecting mean, median, min, max, percentiles, etc.

			    15/    15 done  54:33


Posterior means (95% Equal-tail CI) (95% HPD CI) HPD-CI-width

t_n9           0.3920 ( 0.3551,  0.4137) ( 0.3605,  0.4170)  0.0566  (Jnode 14)
t_n10          0.2527 ( 0.2304,  0.2826) ( 0.2287,  0.2802)  0.0515  (Jnode 13)
t_n11          0.1415 ( 0.1116,  0.1753) ( 0.1096,  0.1731)  0.0635  (Jnode 12)
t_n12          0.1264 ( 0.0988,  0.1580) ( 0.0976,  0.1564)  0.0588  (Jnode 11)
t_n13          0.1126 ( 0.0866,  0.1426) ( 0.0850,  0.1405)  0.0556  (Jnode 10)
t_n14          0.0444 ( 0.0324,  0.0596) ( 0.0312,  0.0581)  0.0269  (Jnode  9)
t_n15          0.0309 ( 0.0215,  0.0432) ( 0.0210,  0.0422)  0.0213  (Jnode  8)
mu1            0.0784 ( 0.0591,  0.1046) ( 0.0574,  0.1017)  0.0443
mu2            0.0551 ( 0.0419,  0.0738) ( 0.0405,  0.0716)  0.0311
mu3            0.2482 ( 0.1831,  0.3329) ( 0.1747,  0.3210)  0.1464
sigma2_1       0.1800 ( 0.0774,  0.3841) ( 0.0625,  0.3391)  0.2765
sigma2_2       0.1686 ( 0.0692,  0.3662) ( 0.0575,  0.3227)  0.2652
sigma2_3       0.2139 ( 0.0944,  0.4402) ( 0.0763,  0.3907)  0.3144
lnL          -19.2425 (-28.6200, -11.6690) (-27.9610, -11.1940) 16.7670

mean	0.3920	0.2527	0.1415	0.1264	0.1126	0.0444	0.0309	0.0784	0.0551	0.2482	0.1800	0.1686	0.2139	-19.2425
Eff 	0.9367	0.7609	0.3827	0.3697	0.3813	0.5773	0.6680	0.7485	0.7570	0.7389	0.9248	0.9376	0.4482	0.9926
time prior: Birth-Death-Sampling
rate prior: Log-Normal
arcsin transform is used in approx like calculation.

Time used: 54:33
